{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8):\n",
    "    qmin = 0.\n",
    "    qmax = 2. ** num_bits - 1.\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "    zero_point = qmax - max_val / scale\n",
    "\n",
    "    if zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "\n",
    "    zero_point = int(zero_point)\n",
    "\n",
    "    return scale, zero_point\n",
    "\n",
    "\n",
    "def quantize_tensor(x, scale, zero_point, num_bits=8, signed=False):\n",
    "    if signed:\n",
    "        qmin = - 2. ** (num_bits - 1)\n",
    "        qmax = 2. ** (num_bits - 1) - 1\n",
    "    else:\n",
    "        qmin = 0.\n",
    "        qmax = 2. ** num_bits - 1.\n",
    "\n",
    "    q_x = zero_point + x / scale\n",
    "\n",
    "    q_x = numpy.clip(q_x, qmin, qmax).round()\n",
    "\n",
    "    return q_x\n",
    "\n",
    "def dequantize_tensor(q_x, scale, zero_point):\n",
    "    return scale * (q_x - zero_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "\n",
    "a = numpy.random.normal(loc=0.0, scale=1.0, size=100000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5958 0\n",
      "247.2403774020081\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "max_val = a.max()\n",
    "min_val = a.min()\n",
    "\n",
    "scale, zero_point = calcScaleZeroPoint(min_val, max_val, k)\n",
    "\n",
    "scale = 1.5958\n",
    "\n",
    "print(scale, zero_point)\n",
    "loss = 0\n",
    "for i in a:\n",
    "    q_i = quantize_tensor(i, scale, zero_point, k)\n",
    "    f_i = dequantize_tensor(q_i, scale, zero_point)\n",
    "    # print(q_i, i)\n",
    "    loss += (numpy.abs(f_i - i) ** 2)\n",
    "loss = loss ** 0.5\n",
    "\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.77853363125806\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scales = [1.5958, 0.9957, 0.586, 0.3352, 0.1881, 0.1041, 0.0569, 0.0308]\n",
    "\n",
    "test = np.random.normal(loc=0.22, scale=0.555, size=100000)\n",
    "\n",
    "def uL2Q(w_f, k):\n",
    "    if k > 8:\n",
    "        scale = w_f.max() - w_f.min()\n",
    "    else:\n",
    "        scale = scales[k-1]\n",
    "\n",
    "    a = scale * (np.std(w_f, ddof=1) ** 0.5)\n",
    "    b = np.mean(w_f)\n",
    "\n",
    "    fai = (w_f - b) / a - 0.5\n",
    "\n",
    "    w_q_ = np.clip(fai, -(2**(k-1)), 2**(k-1) - 1).round()\n",
    "\n",
    "    w_q = a*w_q_ + b\n",
    "\n",
    "    return w_q_, w_q\n",
    "\n",
    "w_q_, w_q = uL2Q(test, 2)\n",
    "\n",
    "# print(w_q_)\n",
    "# print(test)\n",
    "# print(w_q)\n",
    "\n",
    "loss = 0\n",
    "for i in range(100000):\n",
    "    loss += (np.abs(w_q[i] - test[i]) ** 2)\n",
    "loss = loss ** 0.5\n",
    "\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "conv2 = nn.Conv2d(3, 64, 3)\n",
    "\n",
    "def ul2q(w_tensor, num_bits=8):\n",
    "\n",
    "    if num_bits > 8:\n",
    "        scale = w_tensor.max() - w_tensor.min()\n",
    "    else:\n",
    "        scale = scales[num_bits-1]\n",
    "\n",
    "    a = scale * (torch.std(w_tensor) ** 0.5)\n",
    "    b = torch.mean(w_tensor)\n",
    "\n",
    "    fai = (w_tensor - b) / a - 0.5\n",
    "\n",
    "    w_q_ = torch.clamp_(fai, -(2**(num_bits-1)), 2**(num_bits-1) - 1).round()\n",
    "\n",
    "    w_q = a*w_q_ + b\n",
    "\n",
    "    return w_q_, w_q\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "w_q_, w_q = ul2q(conv2.weight.data)\n",
    "\n",
    "conv2.weight.data = w_q_\n",
    "\n",
    "test_data = torch.randn(64, 3, 32, 32)\n",
    "\n",
    "test_data_q = ul2q(test_data)\n",
    "\n",
    "# print(conv2(test_data_q))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}