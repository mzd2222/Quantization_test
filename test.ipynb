{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8):\n",
    "    qmin = 0.\n",
    "    qmax = 2. ** num_bits - 1.\n",
    "    scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "    zero_point = qmax - max_val / scale\n",
    "\n",
    "    if zero_point < qmin:\n",
    "        zero_point = qmin\n",
    "    elif zero_point > qmax:\n",
    "        zero_point = qmax\n",
    "\n",
    "    zero_point = int(zero_point)\n",
    "\n",
    "    return scale, zero_point\n",
    "\n",
    "\n",
    "def quantize_tensor(x, scale, zero_point, num_bits=8, signed=False):\n",
    "    if signed:\n",
    "        qmin = - 2. ** (num_bits - 1)\n",
    "        qmax = 2. ** (num_bits - 1) - 1\n",
    "    else:\n",
    "        qmin = 0.\n",
    "        qmax = 2. ** num_bits - 1.\n",
    "\n",
    "    q_x = zero_point + x / scale\n",
    "\n",
    "    q_x = numpy.clip(q_x, qmin, qmax).round()\n",
    "\n",
    "    return q_x\n",
    "\n",
    "def dequantize_tensor(q_x, scale, zero_point):\n",
    "    return scale * (q_x - zero_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy\n",
    "\n",
    "a = numpy.random.normal(loc=0.0, scale=1.0, size=100000)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5958 0\n",
      "247.2403774020081\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "max_val = a.max()\n",
    "min_val = a.min()\n",
    "\n",
    "scale, zero_point = calcScaleZeroPoint(min_val, max_val, k)\n",
    "\n",
    "scale = 1.5958\n",
    "\n",
    "print(scale, zero_point)\n",
    "loss = 0\n",
    "for i in a:\n",
    "    q_i = quantize_tensor(i, scale, zero_point, k)\n",
    "    f_i = dequantize_tensor(q_i, scale, zero_point)\n",
    "    # print(q_i, i)\n",
    "    loss += (numpy.abs(f_i - i) ** 2)\n",
    "loss = loss ** 0.5\n",
    "\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135.77853363125806\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scales = [1.5958, 0.9957, 0.586, 0.3352, 0.1881, 0.1041, 0.0569, 0.0308]\n",
    "\n",
    "test = np.random.normal(loc=0.22, scale=0.555, size=100000)\n",
    "\n",
    "def uL2Q(w_f, k):\n",
    "    if k > 8:\n",
    "        scale = w_f.max() - w_f.min()\n",
    "    else:\n",
    "        scale = scales[k-1]\n",
    "\n",
    "    a = scale * (np.std(w_f, ddof=1) ** 0.5)\n",
    "    b = np.mean(w_f)\n",
    "\n",
    "    fai = (w_f - b) / a - 0.5\n",
    "\n",
    "    w_q_ = np.clip(fai, -(2**(k-1)), 2**(k-1) - 1).round()\n",
    "\n",
    "    w_q = a*w_q_ + b\n",
    "\n",
    "    return w_q_, w_q\n",
    "\n",
    "w_q_, w_q = uL2Q(test, 2)\n",
    "\n",
    "# print(w_q_)\n",
    "# print(test)\n",
    "# print(w_q)\n",
    "\n",
    "loss = 0\n",
    "for i in range(100000):\n",
    "    loss += (np.abs(w_q[i] - test[i]) ** 2)\n",
    "loss = loss ** 0.5\n",
    "\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "conv2 = nn.Conv2d(3, 64, 3)\n",
    "\n",
    "def ul2q(w_tensor, num_bits=8):\n",
    "\n",
    "    if num_bits > 8:\n",
    "        scale = w_tensor.max() - w_tensor.min()\n",
    "    else:\n",
    "        scale = scales[num_bits-1]\n",
    "\n",
    "    a = scale * (torch.std(w_tensor) ** 0.5)\n",
    "    b = torch.mean(w_tensor)\n",
    "\n",
    "    fai = (w_tensor - b) / a - 0.5\n",
    "\n",
    "    w_q_ = torch.clamp_(fai, -(2**(num_bits-1)), 2**(num_bits-1) - 1).round()\n",
    "\n",
    "    w_q_ = torch.tensor(w_q_, dtype=torch.int8)\n",
    "\n",
    "    w_q = a*w_q_ + b\n",
    "\n",
    "    return w_q_, w_q\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-65-037e295ed45d>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  w_q_ = torch.tensor(w_q_, dtype=torch.int8)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-66-8347ed17969a>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mtest_data_q\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mul2q\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mconv2\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_data_q\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1049\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[0;32m   1050\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[1;32m-> 1051\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1052\u001B[0m         \u001B[1;31m# Do not call functions when jit is used\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1053\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36mforward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    441\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    442\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minput\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 443\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0minput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    444\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    445\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[0mConv3d\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_ConvNd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    437\u001B[0m                             \u001B[0mweight\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbias\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstride\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    438\u001B[0m                             _pair(0), self.dilation, self.groups)\n\u001B[1;32m--> 439\u001B[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001B[0m\u001B[0;32m    440\u001B[0m                         self.padding, self.dilation, self.groups)\n\u001B[0;32m    441\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: conv2d() received an invalid combination of arguments - got (tuple, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (!tuple!, !Parameter!, !Parameter!, !tuple!, !tuple!, !tuple!, int)\n"
     ]
    }
   ],
   "source": [
    "w_q_, w_q = ul2q(conv2.weight.data)\n",
    "\n",
    "conv2.weight.data = w_q_\n",
    "\n",
    "test_data = torch.randn(64, 3, 32, 32)\n",
    "\n",
    "test_data_q = ul2q(test_data)\n",
    "\n",
    "print(conv2(test_data_q))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}